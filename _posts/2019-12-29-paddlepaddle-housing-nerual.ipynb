{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 这篇是用 paddlepaddle 写房价预测\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#加载飞桨、Numpy和相关类库\n",
    "\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.dygraph as dygraph\n",
    "from paddle.fluid.dygraph import FC\n",
    "import numpy as np\n",
    "\n",
    "# 数据加载工具类\n",
    "from  util.housing_util import load_data, load_one_example\n",
    "# 加载数据后的统计值变量，在 load_data 后设置，为最大，最小，平均。用于计算归一化值\n",
    "global all_stastic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 1.数据预处理 ，直接加载之前的工具类，一致的\n",
    "### 2.模型设计\n",
    "\n",
    "这里设计双层网络。一层输入层，一层隐层\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "class Regressor(fluid.dygraph.Layer):\n",
    "    \n",
    "    def __init__(self, name_scope) :\n",
    "        super(Regressor,self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        \n",
    "        # 定义全连接层，这里没加 bias。和设计的算法有点出入，后面看下API 说明加上\n",
    "        self.fc1 = FC(name_scope, size=13, act=None)\n",
    "        self.fc2 = FC(name_scope, size=1, act=None)\n",
    "        \n",
    "        \n",
    "    # 网络前向计算函数\n",
    "    def forward(self, inputs):\n",
    "        a_h = self.fc1(inputs)\n",
    "        y = self.fc2(a_h)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "  \n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.训练配置\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[array([ 88.9762, 100.    ,  25.65  ,   1.    ,   0.871 ,   8.78  ,\n       100.    ,  12.1265,  24.    , 666.    ,  22.    , 396.9   ,\n        37.97  ,  50.    ]), array([6.3200e-03, 0.0000e+00, 4.6000e-01, 0.0000e+00, 3.8500e-01,\n       3.5610e+00, 2.9000e+00, 1.1296e+00, 1.0000e+00, 1.8700e+02,\n       1.2600e+01, 7.0800e+01, 1.7300e+00, 5.0000e+00]), array([1.91589931e+00, 1.42326733e+01, 9.50232673e+00, 8.66336634e-02,\n       5.31731931e-01, 6.33310891e+00, 6.44274752e+01, 4.17421361e+00,\n       6.78960396e+00, 3.52910891e+02, 1.80262376e+01, 3.79971757e+02,\n       1.13549505e+01, 2.41757426e+01])]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = Regressor(\"Regressor\")\n",
    "    \n",
    "    # 开启模型训练模式\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    # 加载数据\n",
    "    training_data, test_data , my_all_stastic = load_data()\n",
    "    \n",
    "    all_stastic = my_all_stastic\n",
    "    print(all_stastic)\n",
    "    # 学习率设置为 0.01\n",
    "    opt = fluid.optimizer.SGD(learning_rate=0.01)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 4.训练并保存模型\n",
    "\n",
    "这里用的 mini-batch 方式直接copy 过来的\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "epoch: 0, iter: 0, loss is: [0.1481473]\nepoch: 1, iter: 0, loss is: [0.10623512]\nepoch: 2, iter: 0, loss is: [0.06507152]\nepoch: 3, iter: 0, loss is: [0.10395487]\nepoch: 4, iter: 0, loss is: [0.07486193]\nepoch: 5, iter: 0, loss is: [0.09647383]\n",
      "epoch: 6, iter: 0, loss is: [0.0592256]\nepoch: 7, iter: 0, loss is: [0.05568671]\nepoch: 8, iter: 0, loss is: [0.05602317]\nepoch: 9, iter: 0, loss is: [0.0466639]\n",
      "epoch: 10, iter: 0, loss is: [0.04839917]\nepoch: 11, iter: 0, loss is: [0.05812053]\nepoch: 12, iter: 0, loss is: [0.05793015]\nepoch: 13, iter: 0, loss is: [0.06924678]\nepoch: 14, iter: 0, loss is: [0.05832703]\nepoch: 15, iter: 0, loss is: [0.0427563]\nepoch: 16, iter: 0, loss is: [0.03139522]\n",
      "epoch: 17, iter: 0, loss is: [0.02521168]\nepoch: 18, iter: 0, loss is: [0.04452838]\nepoch: 19, iter: 0, loss is: [0.03508262]\nepoch: 20, iter: 0, loss is: [0.04956186]\nepoch: 21, iter: 0, loss is: [0.04176604]\n",
      "epoch: 22, iter: 0, loss is: [0.04395108]\nepoch: 23, iter: 0, loss is: [0.01881038]\n",
      "epoch: 24, iter: 0, loss is: [0.04877205]\nepoch: 25, iter: 0, loss is: [0.04403654]\n",
      "epoch: 26, iter: 0, loss is: [0.02880949]\nepoch: 27, iter: 0, loss is: [0.03630515]\nepoch: 28, iter: 0, loss is: [0.04419984]\n",
      "epoch: 29, iter: 0, loss is: [0.04238167]\nepoch: 30, iter: 0, loss is: [0.03977687]\nepoch: 31, iter: 0, loss is: [0.02600098]\n",
      "epoch: 32, iter: 0, loss is: [0.03183369]\nepoch: 33, iter: 0, loss is: [0.01639062]\n",
      "epoch: 34, iter: 0, loss is: [0.02203416]\nepoch: 35, iter: 0, loss is: [0.03184173]\nepoch: 36, iter: 0, loss is: [0.02381719]\n",
      "epoch: 37, iter: 0, loss is: [0.05137089]\nepoch: 38, iter: 0, loss is: [0.04110888]\nepoch: 39, iter: 0, loss is: [0.039241]\nepoch: 40, iter: 0, loss is: [0.03647748]\n",
      "epoch: 41, iter: 0, loss is: [0.03187416]\nepoch: 42, iter: 0, loss is: [0.0309484]\n",
      "epoch: 43, iter: 0, loss is: [0.04838527]\nepoch: 44, iter: 0, loss is: [0.02272531]\n",
      "epoch: 45, iter: 0, loss is: [0.02989025]\nepoch: 46, iter: 0, loss is: [0.02336251]\nepoch: 47, iter: 0, loss is: [0.02699223]\n",
      "epoch: 48, iter: 0, loss is: [0.02866812]\nepoch: 49, iter: 0, loss is: [0.02402335]\nepoch: 50, iter: 0, loss is: [0.04171531]\nepoch: 51, iter: 0, loss is: [0.04470729]\n",
      "epoch: 52, iter: 0, loss is: [0.02488734]\nepoch: 53, iter: 0, loss is: [0.01800954]\nepoch: 54, iter: 0, loss is: [0.02715453]\nepoch: 55, iter: 0, loss is: [0.01856082]\nepoch: 56, iter: 0, loss is: [0.022078]\nepoch: 57, iter: 0, loss is: [0.02643769]\nepoch: 58, iter: 0, loss is: [0.03292308]\n",
      "epoch: 59, iter: 0, loss is: [0.02866376]\nepoch: 60, iter: 0, loss is: [0.02374008]\nepoch: 61, iter: 0, loss is: [0.02626836]\nepoch: 62, iter: 0, loss is: [0.04346812]\nepoch: 63, iter: 0, loss is: [0.01654934]\n",
      "epoch: 64, iter: 0, loss is: [0.01168822]\nepoch: 65, iter: 0, loss is: [0.01541619]\nepoch: 66, iter: 0, loss is: [0.03037399]\n",
      "epoch: 67, iter: 0, loss is: [0.01603233]\nepoch: 68, iter: 0, loss is: [0.02457377]\nepoch: 69, iter: 0, loss is: [0.01566416]\n",
      "epoch: 70, iter: 0, loss is: [0.03497444]\nepoch: 71, iter: 0, loss is: [0.02841765]\n",
      "epoch: 72, iter: 0, loss is: [0.02007245]\nepoch: 73, iter: 0, loss is: [0.01647839]\n",
      "epoch: 74, iter: 0, loss is: [0.02841564]\nepoch: 75, iter: 0, loss is: [0.03026055]\nepoch: 76, iter: 0, loss is: [0.01914282]\n",
      "epoch: 77, iter: 0, loss is: [0.02681017]\nepoch: 78, iter: 0, loss is: [0.02798228]\nepoch: 79, iter: 0, loss is: [0.01753144]\n",
      "epoch: 80, iter: 0, loss is: [0.01593197]\nepoch: 81, iter: 0, loss is: [0.03224338]\nepoch: 82, iter: 0, loss is: [0.0199582]\n",
      "epoch: 83, iter: 0, loss is: [0.02490276]\nepoch: 84, iter: 0, loss is: [0.01723043]\n",
      "epoch: 85, iter: 0, loss is: [0.01921878]\nepoch: 86, iter: 0, loss is: [0.02397879]\nepoch: 87, iter: 0, loss is: [0.02429887]\n",
      "epoch: 88, iter: 0, loss is: [0.01738256]\nepoch: 89, iter: 0, loss is: [0.02251818]\nepoch: 90, iter: 0, loss is: [0.02398938]\n",
      "epoch: 91, iter: 0, loss is: [0.00912767]\nepoch: 92, iter: 0, loss is: [0.01622294]\nepoch: 93, iter: 0, loss is: [0.0202231]\n",
      "epoch: 94, iter: 0, loss is: [0.01655493]\nepoch: 95, iter: 0, loss is: [0.01540987]\nepoch: 96, iter: 0, loss is: [0.02027803]\n",
      "epoch: 97, iter: 0, loss is: [0.01916204]\nepoch: 98, iter: 0, loss is: [0.02039809]\nepoch: 99, iter: 0, loss is: [0.01872693]\n模型保存成功，模型参数保存在LR_model中\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "with dygraph.guard():\n",
    "    EPOCH_NUM = 100   # 设置外层循环次数\n",
    "    BATCH_SIZE = 50  # 设置batch大小\n",
    "    \n",
    "    # 定义外层循环\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\n",
    "        np.random.shuffle(training_data)\n",
    "        # 将训练数据进行拆分，每个batch包含10条数据\n",
    "        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\n",
    "        # 定义内层循环\n",
    "        for iter_id, mini_batch in enumerate(mini_batches):\n",
    "            x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\n",
    "            y = np.array(mini_batch[:, -1:]).astype('float32') # 获得当前批次训练标签（真实房价）\n",
    "            # 将numpy数据转为飞桨动态图variable形式\n",
    "            house_features = dygraph.to_variable(x)\n",
    "            prices = dygraph.to_variable(y)\n",
    "            \n",
    "            # print(house_features)\n",
    "            # 前向计算\n",
    "            predicts = model(house_features)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = fluid.layers.square_error_cost(predicts, label=prices)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            if iter_id%20==0:\n",
    "                print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\n",
    "            \n",
    "            # 反向传播\n",
    "            avg_loss.backward()\n",
    "            # 最小化loss,更新参数\n",
    "            opt.minimize(avg_loss)\n",
    "            # 清除梯度\n",
    "            model.clear_gradients()\n",
    "    # 保存模型\n",
    "    fluid.save_dygraph(model.state_dict(), 'LR_model')\n",
    "    print(\"模型保存成功，模型参数保存在LR_model中\")\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. 测试模型\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-0.01827921 -0.14232673  0.00745031 -0.08663366  0.10960508 -0.18070683\n   0.08725566 -0.12509103 -0.03433061  0.07951798  0.12486834  0.0519112\n   0.2700069 ]] 19.7\n预测结果 is [[16.939106]], 标签结果 is 19.7\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "with dygraph.guard():\n",
    "    model_dict, _ = fluid.load_dygraph(\"LR_model\")\n",
    "    model.load_dict(model_dict)\n",
    "    # 设置到预测状态\n",
    "    model.eval()\n",
    "    \n",
    "    # \n",
    "    one_test_data, label = load_one_example()\n",
    "    print(one_test_data,label)\n",
    "    \n",
    "    one_test_data = dygraph.to_variable(one_test_data)\n",
    "    results = model(one_test_data)\n",
    "    max_values = all_stastic[0]\n",
    "    min_values = all_stastic[1]\n",
    "    avg_values = all_stastic[2]\n",
    "\n",
    "    results = results * (max_values[-1] - min_values[-1]) + avg_values[-1]\n",
    "    \n",
    "    print(\"预测结果 is {}, 标签结果 is {}\".format(results.numpy(), label))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}